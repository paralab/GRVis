In the project proposal, we discussed potentially exploring an advanced topic like In-Situ rendering or visualizing tensor fields but we did not get around to doing this. There ended up being more challenges to getting the parallel rendering pipeline working correctly than anticipated and took up the majority of our time.

Another thing we didn't get around to doing was producing a volume rendering visualization. We used the volume rendering example provided by the VTK Python documentation but none of our attempts managed to produce any output in the rendering window. We had this issue with our other visualizations and fixed it by resetting the camera but this did not work for the volume rendering case. 

Aside from not exploring an advanced topic or producing a volume rendering visualization, we did succeed in producing a parallel rendering framework for producing visualizations of the large GR data set. With this framework, we can create images and videos using some of the simple filters we discussed in class like taking slices and warping by a scalar value.

Ultimately, we succeeded in the main objective of this project which was to create a parallel rendering pipeline for quickly and easily producing visualizations from a very large data set with many data fields (scalar, vector, and tensor). There are still things that can be added but the core functionality we need to create visualizations is in place and ready to use and further develop. Using our pipeline we have produced the images seen in this report as well as some animations which we will include with this submission.